{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROYECTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>land_1</th>\n",
       "      <th>logged_in_1</th>\n",
       "      <th>is_guest_login_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494016</th>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>1881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494017</th>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>2286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494018</th>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494019</th>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494020</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145586 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  wrong_fragment  urgent  hot  \\\n",
       "0              0        181       5450               0       0    0   \n",
       "1              0        239        486               0       0    0   \n",
       "2              0        235       1337               0       0    0   \n",
       "3              0        219       1337               0       0    0   \n",
       "4              0        217       2032               0       0    0   \n",
       "...          ...        ...        ...             ...     ...  ...   \n",
       "494016         0        310       1881               0       0    0   \n",
       "494017         0        282       2286               0       0    0   \n",
       "494018         0        203       1200               0       0    0   \n",
       "494019         0        291       1200               0       0    0   \n",
       "494020         0        219       1234               0       0    0   \n",
       "\n",
       "        num_failed_logins  num_compromised  root_shell  su_attempted  ...  \\\n",
       "0                       0                0           0             0  ...   \n",
       "1                       0                0           0             0  ...   \n",
       "2                       0                0           0             0  ...   \n",
       "3                       0                0           0             0  ...   \n",
       "4                       0                0           0             0  ...   \n",
       "...                   ...              ...         ...           ...  ...   \n",
       "494016                  0                0           0             0  ...   \n",
       "494017                  0                0           0             0  ...   \n",
       "494018                  0                0           0             0  ...   \n",
       "494019                  0                0           0             0  ...   \n",
       "494020                  0                0           0             0  ...   \n",
       "\n",
       "        flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  \\\n",
       "0               0        0        0        0        0        1        0   \n",
       "1               0        0        0        0        0        1        0   \n",
       "2               0        0        0        0        0        1        0   \n",
       "3               0        0        0        0        0        1        0   \n",
       "4               0        0        0        0        0        1        0   \n",
       "...           ...      ...      ...      ...      ...      ...      ...   \n",
       "494016          0        0        0        0        0        1        0   \n",
       "494017          0        0        0        0        0        1        0   \n",
       "494018          0        0        0        0        0        1        0   \n",
       "494019          0        0        0        0        0        1        0   \n",
       "494020          0        0        0        0        0        1        0   \n",
       "\n",
       "        land_1  logged_in_1  is_guest_login_1  \n",
       "0            0            1                 0  \n",
       "1            0            1                 0  \n",
       "2            0            1                 0  \n",
       "3            0            1                 0  \n",
       "4            0            1                 0  \n",
       "...        ...          ...               ...  \n",
       "494016       0            1                 0  \n",
       "494017       0            1                 0  \n",
       "494018       0            1                 0  \n",
       "494019       0            1                 0  \n",
       "494020       0            1                 0  \n",
       "\n",
       "[145586 rows x 115 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from enum import Enum\n",
    "from io import StringIO\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import requests\n",
    "pandas.options.mode.chained_assignment = None\n",
    "\n",
    "PRNG_SEED = 42\n",
    "\n",
    "numpy.random.seed(PRNG_SEED)\n",
    "\n",
    "\n",
    "# create 'data' cache directory\n",
    "if not os.path.exists('data'):\n",
    "    os.path.makedirs('data')\n",
    "\n",
    "DATASET_COLUMNS_FILE = os.path.join(\"data\", \"kddcup1999_columns.txt\")\n",
    "\n",
    "if not os.path.exists(DATASET_COLUMNS_FILE):\n",
    "    with requests.get(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names\") as request:\n",
    "        with open(DATASET_COLUMNS_FILE, 'wb') as file:\n",
    "            file.write(request.content)\n",
    "\n",
    "\n",
    "ColumnType = Enum('ColumnType', 'SYMBOLIC CONTINUOUS')\n",
    "column_types = {}\n",
    "\n",
    "with open(DATASET_COLUMNS_FILE, 'r') as file:\n",
    "    column_labels: str = file.read()\n",
    "\n",
    "column_regex: re.Pattern = re.compile(r\"^(?P<column_name>\\w+): (?P<data_type>\\w+)\\.$\")\n",
    "for column_type in column_labels.splitlines()[1:]:\n",
    "    match = column_regex.match(column_type)\n",
    "    column_types[match.group(\"column_name\")] = ColumnType[match.group(\"data_type\").upper()]\n",
    "\n",
    "\n",
    "DATASET_URL = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
    "DATASET_FILE = os.path.join(\"data\", \"kddcup1999.data_10_percent.csv\")\n",
    "\n",
    "# download dataset if not already cached\n",
    "if not os.path.exists(DATASET_FILE):\n",
    "    with requests.get(DATASET_URL) as response:\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(f\"failed to download dataset: {DATASET_URL}\")\n",
    "        # decompress content\n",
    "        with open(DATASET_FILE, 'wb') as file:\n",
    "            file.write(gzip.decompress(response.content))\n",
    "\n",
    "dataframe = pandas.read_csv(\n",
    "    # file to import from\n",
    "    DATASET_FILE,\n",
    "    # important to specify the CSV file contains no headers\n",
    "    # otherwise, the first record is interpreted as a header\n",
    "    header=None,\n",
    ")\n",
    "dataframe.columns = [*column_types.keys(), \"outcome\"]\n",
    "\n",
    "pandas.set_option('display.max_rows', 10)\n",
    "\n",
    "unique_dataframe = dataframe.drop_duplicates()\n",
    "\n",
    "encoded_dataframe = pandas.get_dummies(\n",
    "    unique_dataframe,\n",
    "    # all categorical columns\n",
    "    columns=[column_name for column_name, column_type in column_types.items() if column_type == ColumnType.SYMBOLIC],\n",
    "    # drop original column\n",
    "    drop_first=True,\n",
    ")\n",
    "\n",
    "pandas.set_option('display.max_rows', 10)\n",
    "encoded_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = numpy.random.rand(len(unique_dataframe)) < 0.1\n",
    "dff = unique_dataframe[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_use = [\"service\", \"src_bytes\", \"dst_bytes\", \"rerror_rate\", \"dst_host_srv_count\", \"dst_host_diff_srv_rate\"]\n",
    "#col2u=[column_name for column_name, column_type in column_types.items() if column_type == ColumnType.CONTINUOUS]\n",
    "#print(col2u)\n",
    "col2u=[\"src_bytes\", \"dst_bytes\", \"rerror_rate\", \"dst_host_srv_count\", \"dst_host_diff_srv_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    msk = numpy.random.rand(len(unique_dataframe)) < 0.1\n",
    "    df = unique_dataframe[msk]\n",
    "\n",
    "    df[col2u] = df[col2u].astype(float)\n",
    "    pandas.options.mode.chained_assignment = None\n",
    "    min_col = {}\n",
    "    max_col = {}\n",
    "    for index, row in df.iterrows():\n",
    "        for col in col2u:\n",
    "            if col not in min_col or min_col[col] > row[col]:\n",
    "                min_col[col] = row[col]\n",
    "            if col not in max_col or max_col[col] < row[col]:\n",
    "                max_col[col] = row[col]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        row = df[col][df.iloc[i].name]\n",
    "        for col in col2u:\n",
    "            df[col][df.iloc[i].name] = float(abs(float(df[col][df.iloc[i].name]-min_col[col])) / (abs(float(max_col[col] - min_col[col])) if abs(max_col[col] - min_col[col]) else 1))\n",
    "\n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 16\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness_func([unique_dataframe.iloc[0], unique_dataframe.iloc[7448]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_particle = [unique_dataframe.iloc[0], unique_dataframe.iloc[7448]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npandas.options.mode.chained_assignment = None\\nmin_col = {}\\nmax_col = {}\\nfor index, row in df.iterrows():\\n    for col in col2u:\\n        if col not in min_col or min_col[col] > row[col]:\\n            min_col[col] = row[col]\\n        if col not in max_col or max_col[col] < row[col]:\\n            max_col[col] = row[col]\\n\\nfor i in range(len(df)):\\n    row = df[col][df.iloc[i].name]\\n    for col in col2u:\\n        #print(row[col])\\n        #tmp = float(abs(float(df[col][df.iloc[i].name]-min_col[col])) / (abs(float(max_col[col] - min_col[col])) if abs(max_col[col] - min_col[col]) else 1))\\n        #print(tmp)\\n        df[col][df.iloc[i].name] = float(abs(float(df[col][df.iloc[i].name]-min_col[col])) / (abs(float(max_col[col] - min_col[col])) if abs(max_col[col] - min_col[col]) else 1))\\n        #print(row[col])\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pandas.options.mode.chained_assignment = None\n",
    "min_col = {}\n",
    "max_col = {}\n",
    "for index, row in df.iterrows():\n",
    "    for col in col2u:\n",
    "        if col not in min_col or min_col[col] > row[col]:\n",
    "            min_col[col] = row[col]\n",
    "        if col not in max_col or max_col[col] < row[col]:\n",
    "            max_col[col] = row[col]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df[col][df.iloc[i].name]\n",
    "    for col in col2u:\n",
    "        #print(row[col])\n",
    "        #tmp = float(abs(float(df[col][df.iloc[i].name]-min_col[col])) / (abs(float(max_col[col] - min_col[col])) if abs(max_col[col] - min_col[col]) else 1))\n",
    "        #print(tmp)\n",
    "        df[col][df.iloc[i].name] = float(abs(float(df[col][df.iloc[i].name]-min_col[col])) / (abs(float(max_col[col] - min_col[col])) if abs(max_col[col] - min_col[col]) else 1))\n",
    "        #print(row[col])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnot_normal_out = []\\nnormal_out = []\\nfor index, row in df.iterrows():\\n    if row[\"outcome\"] != \"normal.\":\\n        not_normal_out.append(row[col2u+[\\'outcome\\']])\\n    else:\\n        normal_out.append(row[col2u+[\\'outcome\\']])\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "not_normal_out = []\n",
    "normal_out = []\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"outcome\"] != \"normal.\":\n",
    "        not_normal_out.append(row[col2u+['outcome']])\n",
    "    else:\n",
    "        normal_out.append(row[col2u+['outcome']])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_particles = 15\\nstart_particles = []\\nimport random\\nfor _ in range(num_particles):\\n    p = []\\n    normal_index = normal_out[random.randint(0,len(normal_out))]\\n    not_normal_index = not_normal_out[random.randint(0,len(not_normal_out))]\\n    p.append(normal_index)\\n    p.append(not_normal_index)\\n    start_particles.append(p)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_particles = 15\n",
    "start_particles = []\n",
    "import random\n",
    "for _ in range(num_particles):\n",
    "    p = []\n",
    "    normal_index = normal_out[random.randint(0,len(normal_out))]\n",
    "    not_normal_index = not_normal_out[random.randint(0,len(not_normal_out))]\n",
    "    p.append(normal_index)\n",
    "    p.append(not_normal_index)\n",
    "    start_particles.append(p)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_normal_out = None\n",
    "normal_out = None\n",
    "def get_start_particles(not_normal_out = None, normal_out = None, num_particles = 16):\n",
    "    if not not_normal_out or not normal_out:\n",
    "        not_normal_out = []\n",
    "        normal_out = []\n",
    "        for index, row in df.iterrows():\n",
    "            if row[\"outcome\"] != \"normal.\":\n",
    "                not_normal_out.append(row[col2u+['outcome']])\n",
    "            else:\n",
    "                normal_out.append(row[col2u+['outcome']])\n",
    "\n",
    "    start_particles = []\n",
    "    import random\n",
    "    for _ in range(num_particles):\n",
    "        p = []\n",
    "        normal_index = normal_out[random.randint(0,len(normal_out))]\n",
    "        not_normal_index = not_normal_out[random.randint(0,len(not_normal_out))]\n",
    "        p.append(normal_index)\n",
    "        p.append(not_normal_index)\n",
    "        start_particles.append(p)\n",
    "    \n",
    "    return start_particles, not_normal_out, normal_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_particles, not_normal_out, normal_out = get_start_particles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8837"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fitness_func(particle_classes):\n",
    "    num_err = 0\n",
    "    total = 0\n",
    "    for index, row in df.iterrows():\n",
    "        min_dist = None\n",
    "        for particle in particle_classes:\n",
    "            dist = 0\n",
    "            for c in col2u:\n",
    "                dist += (float(particle[c])-float(row[c]))**2\n",
    "            dist = dist**.5\n",
    "            if min_dist == None or dist < min_dist[0]:\n",
    "                min_dist = [\n",
    "                    dist, \n",
    "                    str(particle[\"outcome\"])\n",
    "                ]\n",
    "        if str(min_dist[1]) != str(row[\"outcome\"]):\n",
    "            num_err +=1\n",
    "        total += 1\n",
    "    return num_err/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "class PSO:\n",
    "\n",
    "    def __init__(self, particles, velocities, fitness_function,\n",
    "                 w=0.8, c_1=1, c_2=1, max_iter=100, auto_coef=True):\n",
    "        self.particles = particles\n",
    "        self.velocities = velocities\n",
    "        self.fitness_function = fitness_function\n",
    "        \n",
    "        self.iter = 0\n",
    "        time_int = int(round(datetime.datetime.now().timestamp()))\n",
    "        file_name_part = f\"PSO_{time_int}_particles.csv\"\n",
    "        file_name_bests = f\"PSO_{time_int}_bests.csv\"\n",
    "        self.iterations_csv = open(file_name_part, \"w+\")\n",
    "        self.bests_csv = open(file_name_bests, \"w+\")\n",
    "        self.iterations_csv.write(\"iteration,particleNo,error\\n\")\n",
    "        self.bests_csv.write(\"iteration,error\\n\")\n",
    "\n",
    "        self.N = len(self.particles)\n",
    "        self.w = w\n",
    "        self.c_1 = c_1\n",
    "        self.c_2 = c_2\n",
    "        self.auto_coef = auto_coef\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "\n",
    "        self.p_bests = self.particles\n",
    "        self.p_bests_values = [self.fitness_function(i) for i in self.particles]\n",
    "        for i in range(len(self.p_bests_values)):\n",
    "            self.iterations_csv.write(f\"{self.iter},{i},{self.p_bests_values[i]}\\n\")\n",
    "        self.g_best = self.p_bests[0]\n",
    "        self.g_best_value = self.p_bests_values[0]\n",
    "        self.update_bests()\n",
    "\n",
    "        self.is_running = True\n",
    "        self.update_coef()\n",
    "\n",
    "    def close_files():\n",
    "        self.iterations_csv.close()\n",
    "        self.bests_csv.close()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'[{self.iter}/{self.max_iter}] $w$:{self.w:.3f} - $c_1$:{self.c_1:.3f} - $c_2$:{self.c_2:.3f}'\n",
    "\n",
    "    def next(self):\n",
    "        self.bests_csv.write(f\"{self.iter},{self.g_best_value}\\n\")\n",
    "        if self.iter > 0:\n",
    "            self.move_particles()\n",
    "            self.update_bests()\n",
    "            self.update_coef()\n",
    "\n",
    "        self.iter += 1\n",
    "        self.is_running = self.is_running and self.iter < self.max_iter\n",
    "        return self.is_running\n",
    "\n",
    "    def update_coef(self):\n",
    "        if self.auto_coef:\n",
    "            t = self.iter\n",
    "            n = self.max_iter\n",
    "            self.w = (0.4/n**2) * (t - n) ** 2 + 0.4\n",
    "            self.c_1 = -3 * t / n + 3.5\n",
    "            self.c_2 =  3 * t / n + 0.5\n",
    "\n",
    "    def move_particles(self):\n",
    "\n",
    "        # add inertia\n",
    "        new_velocities = self.w * self.velocities\n",
    "        # add cognitive component\n",
    "        r_1 = np.random.random(self.N)\n",
    "        r_1 = np.tile(r_1[:, None], (1, 20))\n",
    "        for index in range(len(self.particles)):\n",
    "            for subi in range(len(self.particles[index])):\n",
    "                for ci in range(len(col2u)):\n",
    "                    c = col2u[ci]\n",
    "                    new_velocities[index][ci] += self.c_1 * r_1[index][ci] * (self.p_bests[index][subi][c] - self.particles[index][subi][c])\n",
    "\n",
    "        # add social component\n",
    "        r_2 = np.random.random(self.N)\n",
    "        r_2 = np.tile(r_2[:, None], (1, 20))\n",
    "        g_best = self.g_best\n",
    "        for index in range(len(self.particles)):\n",
    "            for subi in range(len(self.particles[index])):\n",
    "                for ci in range(len(col2u)):\n",
    "                    c = col2u[ci]\n",
    "                    new_velocities[index][ci] += self.c_2 * r_2[index][ci] * (g_best[subi][ci]  - self.particles[index][subi][c])\n",
    "\n",
    "        self.is_running = np.sum(self.velocities - new_velocities) != 0\n",
    "\n",
    "        # update positions and velocities\n",
    "        self.velocities = new_velocities\n",
    "        for index in range(len(self.particles)):\n",
    "            for subi in range(len(self.particles[index])):\n",
    "                for ci in range(len(col2u)):\n",
    "                    c = col2u[ci]\n",
    "                    self.particles[index][subi][c] = self.particles[index][subi][c] + new_velocities[index][ci]\n",
    "\n",
    "\n",
    "    def update_bests(self):\n",
    "        fits = [self.fitness_function(i) for i in self.particles]\n",
    "\n",
    "        for i in range(len(self.particles)):\n",
    "            self.iterations_csv.write(f\"{self.iter},{i},{fits[i]}\\n\")\n",
    "            # update best personnal value (cognitive)\n",
    "            if fits[i] < self.p_bests_values[i]:\n",
    "                self.p_bests_values[i] = fits[i]\n",
    "                self.p_bests[i] = self.particles[i]\n",
    "                # update best global value (social)\n",
    "                if fits[i] < self.g_best_value:\n",
    "                    self.g_best_value = fits[i]\n",
    "                    self.g_best = self.particles[i]\n",
    "\n",
    "\n",
    "def opt_funct(x):\n",
    "    return fitness_func(x)\n",
    "\n",
    "num_particles = 16\n",
    "num_features = len(col2u)\n",
    "\n",
    "velocities = (np.random.random((num_particles, num_features)) - 0.5) / 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport datetime\\nprint(datetime.datetime.now())\\npso = PSO(start_particles, velocities, opt_funct, max_iter=15, w = .8, c_1=1, c_2=1)\\nprint(datetime.datetime.now())\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "pso = PSO(start_particles, velocities, opt_funct, max_iter=15, w = .8, c_1=1, c_2=1)\n",
    "print(datetime.datetime.now())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 0\\nwhile pso.next():\\n    print(\"ITER: \", i, \" pso: \", pso.p_bests_values[0])\\n    i += 1\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "i = 0\n",
    "while pso.next():\n",
    "    print(\"ITER: \", i, \" pso: \", pso.p_bests_values[0])\n",
    "    i += 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    start_particles, not_normal_out, normal_out = get_start_particles(num_particles = 16, not_normal_out = not_normal_out, normal_out = normal_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def call_pso(not_normal_out, normal_out):\n",
    "    num_particles = 16\n",
    "    num_features = len(col2u)\n",
    "\n",
    "    velocities = (np.random.random((num_particles, num_features)) - 0.5) / 10\n",
    "    start_particles, not_normal_out, normal_out = get_start_particles(num_particles = 16, not_normal_out = not_normal_out, normal_out = normal_out)\n",
    "    start_time = time.time()\n",
    "    pso = PSO(start_particles, velocities, opt_funct, max_iter=15, w = .8, c_1=1, c_2=1)\n",
    "    i = 0\n",
    "    while pso.next():\n",
    "        i += 1\n",
    "    end_time = time.time()\n",
    "    return start_time - end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avg_exec_pso = 0\\nfor _ in range(ITERATIONS):\\n    avg_exec_pso += call_pso(not_normal_out, normal_out)\\navg_exec_pso = avg_exec_pso / ITERATIONS\\nprint(\"AVERAGE TIME PSO: \"+avg_exec_pso)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ITERATIONS = 10\n",
    "\"\"\"avg_exec_pso = 0\n",
    "for _ in range(ITERATIONS):\n",
    "    avg_exec_pso += call_pso(not_normal_out, normal_out)\n",
    "avg_exec_pso = avg_exec_pso / ITERATIONS\n",
    "print(\"AVERAGE TIME PSO: \"+avg_exec_pso)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def selection(pop, scores, k=3):\n",
    "    selection_ix = randint(len(pop))\n",
    "    for ix in randint(0, len(pop), k-1):\n",
    "        if scores[ix] < scores[selection_ix]:\n",
    "            selection_ix = ix\n",
    "    return pop[selection_ix]\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    mid = len(col2u)/2\n",
    "    p1_new = []\n",
    "    p2_new = []\n",
    "    for i in range(len(p1)):\n",
    "        p1_new.append([])\n",
    "        p2_new.append([])\n",
    "        for ci in range(len(col2u+['outcome'])):\n",
    "            c = (col2u+['outcome'])[ci]\n",
    "            if ci < mid:\n",
    "                p1_new[i].append(p2[i][c])\n",
    "                p2_new[i].append(p1[i][c])\n",
    "            else:\n",
    "                p1_new[i].append(p1[i][c])\n",
    "                p2_new[i].append(p2[i][c])\n",
    "    df_tmp1 = pandas.DataFrame(p1_new, columns = col2u+['outcome'])\n",
    "    df_tmp2 = pandas.DataFrame(p2_new, columns = col2u+['outcome'])\n",
    "    return [df_tmp1.iloc[0], df_tmp1.iloc[1]], [df_tmp2.iloc[0], df_tmp2.iloc[1]]\n",
    "\n",
    "\n",
    "def mutation(a, r_mut):\n",
    "    for i in range(len(a)):\n",
    "        for c in col2u:\n",
    "            if rand() < r_mut:\n",
    "                a[i][c] = random.uniform(0,1)\n",
    "\n",
    "def genetic_algorithm(fitess_function, particles, n_iter, r_mut):\n",
    "    time_int = int(round(datetime.datetime.now().timestamp()))\n",
    "    file_name_part = f\"GA_{time_int}_particles.csv\"\n",
    "    file_name_bests = f\"GA_{time_int}_bests.csv\"\n",
    "    iterations_csv = open(file_name_part, \"w+\")\n",
    "    bests_csv = open(file_name_bests, \"w+\")\n",
    "    iterations_csv.write(\"iteration,particleNo,error\\n\")\n",
    "    bests_csv.write(\"iteration,error\\n\")\n",
    "    best, best_eval = 1, fitess_function(particles[0])\n",
    "    for gen in range(n_iter):\n",
    "        scores = [fitess_function(c) for c in particles]\n",
    "        for i in range(len(scores)):\n",
    "            iterations_csv.write(f\"{gen},{i},{scores[i]}\\n\")\n",
    "        for i in range(len(scores)):\n",
    "            if scores[i] < best_eval:\n",
    "                best, best_eval = particles[i], scores[i]\n",
    "        bests_csv.write(f\"{gen},{best_eval}\\n\")\n",
    "        selected = [selection(particles, scores) for _ in range(len(particles))]\n",
    "        children = list()\n",
    "        for i in range(0, len(particles), 2):\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            for c in crossover(p1, p2):\n",
    "                mutation(c, r_mut)\n",
    "                children.append(c)\n",
    "        particles = children\n",
    "    iterations_csv.close()\n",
    "    bests_csv.close()\n",
    "    return [best, best_eval]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_particles, not_normal_out, normal_out = get_start_particles(num_particles = 16, not_normal_out = not_normal_out, normal_out = normal_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genetic_algorithm(fitness_func, start_particles, n_iter, r_mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ga(not_normal_out, normal_out):\n",
    "    num_particles = 16\n",
    "    \n",
    "    n_iter = 15\n",
    "    n_bits = 10\n",
    "    n_pop = 100\n",
    "    r_cross = 0.9\n",
    "    r_mut = 1.0 / float(n_bits)\n",
    "    \n",
    "    start_particles, not_normal_out, normal_out = get_start_particles(num_particles = 16, not_normal_out = not_normal_out, normal_out = normal_out)\n",
    "    start_time = time.time()\n",
    "    genetic_algorithm(fitness_func, start_particles, n_iter, r_mut)\n",
    "    end_time = time.time()\n",
    "    return start_time - end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_exec_ga = 0\n",
    "for _ in range(ITERATIONS):\n",
    "    avg_exec_ga += call_ga(not_normal_out, normal_out)\n",
    "avg_exec_ga = avg_exec_ga / ITERATIONS\n",
    "print(\"AVERAGE TIME GA: \"+avg_exec_ga)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
